<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Alpha Mix Research</title>
    <script src="https://code.jquery.com/jquery-3.3.1.js"
        integrity="sha256-2Kok7MbOyxpgUVvAk/HJ2jigOSYS2auK4Pfzbm7uH60=" crossorigin="anonymous">
    </script>
    <script>
        $(function () {
            $("#header").load("header.html");
            $("#footer").load("footer.html");
        });
    </script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link rel="stylesheet" href="./src/css/main.min.css">

</head>

<body>
    <div class="container" id="wrapper">
        <header>
            <div id="header"></div>
        </header>

        <main>
            <div class="content" id="cifar100-content">
                <div class="row">
                    <h2 class="display-5">CIFAR 100</h2>
                </div>

                <div class="row">
                    <div class="col-md-6 col-sm-12">
                        <p>
                            This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images
                            each.<br><br>
                            There are 500 training images and 100 testing images per class.<br><br>
                            The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a
                            "fine" label (the class to which it belongs) and a "coarse" label (the superclass to which
                            it belongs).<br><br>
                        </p>
                    </div>

                    <div class="col-md-6 col-sm-12">
                        <img src="./src/images/cifar100.png" alt="cifar100 example" class="cifar100-example">
                        <p class="img-desc"> Samples from the CIFAR100 dataset</p>
                    </div>
                </div>

                <div class="row">
                    <p>
                        I evaluated Alpha-Mix in three scenarios on this dataset.<br> Initially, I examined its
                        performance
                        with all available data, starting with 10% labeled data and incrementally adding 10% more in
                        each round using Vision Transformers model.
                        <br>
                        The second test aimed to assess Alpha-Mix's performance in a low-data regime, following the
                        recommendations in the article, also using Vision Transformers model. <br>
                        In the third option, I executed ResNet on CIFAR100 to assess whether there was any performance
                        improvement compared to Vision Transformers.<br>

                        To view the results, please select an option:</p>

                    <div class="row"><a class="options" href="#performance-all-data"
                            onclick="showExplanation('all-data')">Performance on
                            All Data</a></div>

                    <div class="row"><a class="options" href="#performance-low-data"
                            onclick="showExplanation('low-data')">Performance on
                            Low Data Regime</a></div>

                    <div class="row"><a class="options" href="#performance-low-data"
                            onclick="showExplanation('low-data-res')">Performance on
                            Low Data Regime with ResNet</a></div>
                </div>


                <!-- Explanation sections -->
                <div class="explanation" id="all-data">
                    <br>
                    <h2>Performance on All Data</h2>
                    <div class="row">
                        <p>
                            In this experiment, a more challenging dataset, the Vision Transformers model, was chosen to
                            assess Alpha-Mix's performance. Similar to previous tests, Alpha-Mix was evaluated by
                            incrementally adding 10% more labeled data in each round. Starting with 10% of the CIFAR100
                            dataset (5000 samples), an additional 5000 samples (10% of the data) were added in each
                            iteration, culminating in the model being trained with 45,000 labeled samples by the 8th
                            round. The following parameters were utilized:</p>
                    </div>
                    <div class="row">
                        <div class="col-md-4 col-sm-12">
                            <ul>
                                <li>Dataset = CIFAR100</li>
                                <li>Model = Vision Transformers</li>
                                <li>Initial label data = 5000 samples</li>
                                <li>Number of queries each round = 5000 samples</li>
                                <li>Number of rounds = 8 rounds</li>
                                <li>Learning rate = 0.001</li>
                                <li>Number of epochs = 50</li>
                                <li>Strategy = AlphaMixSampling compare to RandomSampling</li>
                            </ul>
                        </div>
                        <div class="col-md-8 col-sm-12">
                            <img src="./src/images/all_plot_cifar100.png" alt="cifar100 comparison plots"
                                class="cifar100-comparison">
                        </div>
                    </div>
                    <div class="row">
                        <p><br>
                            It is noticeable that Alpha-Mix samples exhibit a more consistent learning curve compared to
                            random samples. However, it's important to note that in some rounds, the test scores for
                            random samples are higher, and overall, there isn't a significant improvement observed
                            between Alpha-Mix and random samples.

                            The inconsistencies, characterized by sharp decreases and increases in performance for both
                            methods, can be attributed to the learning algorithm encountering local minimum or maximum
                            points. These 'jumps' in performance can potentially be addressed by either increasing the
                            number of epochs or adjusting the learning rate.
                        </p>
                    </div>
                </div>

                <div class="explanation" id="low-data">
                    <br>
                    <h2>Performance on Low Data Regime</h2>
                    <div class="row">
                        <p>
                            Similar to the CIFAR10 experiment, this study aims to assess the performance difference
                            between Alpha-Mix and random sampling, particularly in a low data regime. The approach
                            involves starting with 1000 samples and incrementally adding 1000 more in each round,
                            ultimately reaching Alpha-Mix training on 11,000 labeled samples. This range represents a
                            focus between 2% and 22% of labeled data. Given the reduced computational resources due to
                            fewer interpolations, a trade-off is employed to enhance the number of epochs.</p>
                    </div>
                    <div class="row">
                        <div class="col-md-4 col-sm-12">
                            <ul>
                                <li>Dataset = CIFAR100</li>
                                <li>Model = Vision Transformers</li>
                                <li>Initial label data = 1000 samples</li>
                                <li>Number of queries each round = 1000 samples</li>
                                <li>Number of rounds = 10 rounds</li>
                                <li>Learning rate = 0.001</li>
                                <li>Number of epochs = 1000</li>
                                <li>Strategy = AlphaMixSampling compare to RandomSampling</li>
                            </ul>
                        </div>
                        <div class="col-md-8 col-sm-12">
                            <img src="./src/images/low_plot_cifar100_2.png" alt="cifar100 comparison plots"
                                class="cifar100-comparison">
                        </div>
                    </div>
                    <div class="row">
                        <p><br>
                            In this situation, I trained a model with fewer samples but for a longer time. It's
                            important to mention that the problems I saw in the previous graph, where I used the entire
                            dataset, seem to have improved with these changes. Additionally, I notice that Alpha-Mix
                            samples show more stable learning compared to random samples. To sum up, in this case when
                            there's not much data available, Alpha-Mix performs better in terms of accuracy compared to
                            random sampling, although the difference is small.
                        </p>
                    </div>
                </div>

                <div class="explanation" id="low-data-res">
                    <br>
                    <h2>Performance on Low Data Regime with ResNet</h2>
                    <div class="row">
                        <p>
                            Due to unsatisfactory results on CIFAR100 using Vision Transformers, I attempted the same
                            task with ResNet but only on low data regime, as running the model on the entire dataset
                            exceeded the computational capacity.</p>
                    </div>
                    <div class="row">
                        <div class="col-md-4 col-sm-12">
                            <ul>
                                <li>Dataset = CIFAR100</li>
                                <li>Model = ResNet</li>
                                <li>Initial label data = 1000 samples</li>
                                <li>Number of queries each round = 1000 samples</li>
                                <li>Number of rounds = 10 rounds</li>
                                <li>Learning rate = 0.001</li>
                                <li>Number of epochs = 1000</li>
                                <li>Strategy = AlphaMixSampling compare to RandomSampling</li>
                            </ul>
                        </div>
                        <div class="col-md-8 col-sm-12">
                            <img src="./src/images/low_cifar100_resnet.png" alt="cifar100 ResNet comparison plots"
                                class="cifar100-resnet-comparison">
                        </div>
                    </div>
                    <div class="row">
                        <p><br>
                            Alpha-mix offers no advantage over random sampling, but it does yield final results
                            approximately 2x better than those achieved by the Vision Transformers model on CIFAR100.
                            This suggests that Vision Transformers are not an effective choice for CIFAR100 training.
                        </p>
                    </div>
                </div>
            </div>
        </main>

        <footer>
            <div id="footer"></div>
        </footer>


        <!-- Add Bootstrap and custom scripts (if needed) -->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous">
        </script>
        <script src="./src/js/script.js"></script>


</body>

</html>